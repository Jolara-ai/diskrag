#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PQ æ¨¡å‹ä¿®å¾©è…³æœ¬
é‡æ–°è¨“ç·´ä¸¦ä¿å­˜ PQ æ¨¡å‹ï¼Œç¢ºä¿ç·¨ç¢¼ä¸€è‡´æ€§
"""

import numpy as np
import logging
import sys
from pathlib import Path
from pydiskann.pq.fast_pq import DiskANNPQ
from pydiskann.io.diskann_persist import DiskANNPersist, MMapNodeReader
from preprocessing.collection import CollectionManager

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("PQFixer")

def fix_pq_model(collection_name: str):
    """ä¿®å¾©æŒ‡å®šé›†åˆçš„ PQ æ¨¡å‹"""
    logger.info(f"ğŸ”§ é–‹å§‹ä¿®å¾©é›†åˆ '{collection_name}' çš„ PQ æ¨¡å‹...")
    
    try:
        manager = CollectionManager()
        info = manager.get_collection_info(collection_name)
        if not info:
            logger.error(f"âŒ æ‰¾ä¸åˆ°é›†åˆ: {collection_name}")
            return False
        
        # è¼‰å…¥åŸå§‹å‘é‡æ•¸æ“š
        vectors_path = manager.get_vectors_path(collection_name)
        
        if not vectors_path.exists():
            logger.error(f"âŒ å‘é‡æ–‡ä»¶ä¸å­˜åœ¨: {vectors_path}")
            return False
            
        vectors = np.load(str(vectors_path))
        
        # æª¢æŸ¥å‘é‡æ•¸æ“šæ˜¯å¦ç‚ºç©ºæˆ–æå£
        if vectors.size == 0:
            logger.error(f"âŒ å‘é‡æ•¸æ“šç‚ºç©ºï¼æ–‡ä»¶: {vectors_path}")
            logger.error("è«‹æª¢æŸ¥å‘é‡æ•¸æ“šæ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”åŒ…å«æœ‰æ•ˆæ•¸æ“š")
            return False
        
        # æª¢æŸ¥å‘é‡æ•¸é‡æ˜¯å¦èˆ‡é›†åˆä¿¡æ¯ä¸€è‡´
        if info and len(vectors) != info.num_vectors:
            logger.warning(f"âš ï¸  å‘é‡æ•¸é‡ä¸åŒ¹é…: æ–‡ä»¶ä¸­æœ‰ {len(vectors)} å€‹ï¼Œé›†åˆä¿¡æ¯é¡¯ç¤º {info.num_vectors} å€‹")
            logger.warning("é€™å¯èƒ½è¡¨ç¤ºå‘é‡æ–‡ä»¶æå£ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆ")
            
            # å˜—è©¦å¾ç´¢å¼•æ–‡ä»¶ä¸­æ¢å¾©å‘é‡
            logger.info("ğŸ”§ å˜—è©¦å¾ç´¢å¼•æ–‡ä»¶ä¸­æ¢å¾©å‘é‡...")
            try:
                index_dir = manager.get_index_dir(collection_name)
                reader = MMapNodeReader(str(index_dir / "index.dat"), dim=info.dimension)
                
                # è®€å–æ‰€æœ‰å‘é‡
                recovered_vectors = []
                for i in range(info.num_vectors):
                    vec, _ = reader.get_node(i)
                    recovered_vectors.append(vec)
                
                vectors = np.array(recovered_vectors, dtype=np.float32)
                reader.close()
                
                logger.info(f"âœ… æˆåŠŸå¾ç´¢å¼•æ¢å¾© {len(vectors)} å€‹å‘é‡")
                
                # ä¿å­˜æ¢å¾©çš„å‘é‡
                np.save(str(vectors_path), vectors)
                logger.info(f"ğŸ’¾ å·²ä¿å­˜æ¢å¾©çš„å‘é‡åˆ°: {vectors_path}")
                
            except Exception as e:
                logger.error(f"âŒ ç„¡æ³•å¾ç´¢å¼•æ¢å¾©å‘é‡: {e}")
                return False
        
        # ç¢ºä¿æ•¸æ“šé¡å‹ç‚º float32
        if vectors.dtype != np.float32:
            logger.info(f"ğŸ”„ è½‰æ›æ•¸æ“šé¡å‹å¾ {vectors.dtype} åˆ° float32")
            vectors = vectors.astype(np.float32)
        
        logger.info(f"ğŸ“Š å‘é‡æ•¸æ“šçµ±è¨ˆ:")
        logger.info(f"  - å½¢ç‹€: {vectors.shape}")
        logger.info(f"  - æ•¸æ“šé¡å‹: {vectors.dtype}")
        logger.info(f"  - å‘é‡æ•¸é‡: {len(vectors)}")
        
        # å®‰å…¨åœ°è¨ˆç®—çµ±è¨ˆä¿¡æ¯
        if len(vectors) > 0:
            try:
                min_val = vectors.min()
                max_val = vectors.max()
                mean_val = vectors.mean()
                std_val = vectors.std()
                
                logger.info(f"  - ç¯„åœ: [{min_val:.6f}, {max_val:.6f}]")
                logger.info(f"  - å‡å€¼: {mean_val:.6f}")
                logger.info(f"  - æ¨™æº–å·®: {std_val:.6f}")
            except Exception as e:
                logger.error(f"âŒ è¨ˆç®—å‘é‡çµ±è¨ˆä¿¡æ¯å¤±æ•—: {e}")
                return False
        else:
            logger.error("âŒ æ²’æœ‰æœ‰æ•ˆçš„å‘é‡æ•¸æ“š")
            return False
        
        # è¼‰å…¥å…ƒæ•¸æ“šä»¥ç²å– PQ åƒæ•¸
        index_dir = manager.get_index_dir(collection_name)
        persist = DiskANNPersist(dim=info.dimension)
        meta = persist.load_meta(str(index_dir / "meta.json"))
        
        n_subvectors = meta.get("n_subvectors", 16)
        n_centroids = meta.get("pq_centroids", 256)
        
        logger.info(f"ğŸ¯ é‡æ–°è¨“ç·´ PQ æ¨¡å‹ ({n_subvectors}Ã—{n_centroids})...")
        
        # å‰µå»ºæ–°çš„ PQ æ¨¡å‹
        pq_model = DiskANNPQ(n_subvectors=n_subvectors, n_centroids=n_centroids)
        
        # è¨“ç·´æ¨¡å‹
        pq_model.fit(vectors, show_progress=True)
        
        # é©—è­‰è¨“ç·´çµæœ
        logger.info("ğŸ” é©—è­‰ PQ æ¨¡å‹è¨“ç·´çµæœ...")
        logger.info(f"  - is_fitted: {pq_model.is_fitted}")
        logger.info(f"  - kmeans_list é•·åº¦: {len(pq_model.kmeans_list)}")
        logger.info(f"  - means_ å­˜åœ¨: {hasattr(pq_model, 'means_') and pq_model.means_ is not None}")
        logger.info(f"  - stds_ å­˜åœ¨: {hasattr(pq_model, 'stds_') and pq_model.stds_ is not None}")
        
        # æ¸¬è©¦ç·¨ç¢¼
        logger.info("ğŸ§ª æ¸¬è©¦ç·¨ç¢¼åŠŸèƒ½...")
        test_vectors = vectors[:5]
        test_codes = pq_model.encode(test_vectors)
        logger.info(f"âœ… æ¸¬è©¦ç·¨ç¢¼æˆåŠŸï¼Œå½¢ç‹€: {test_codes.shape}")
        
        # æ¸¬è©¦è§£ç¢¼
        test_decoded = pq_model.decode(test_codes)
        reconstruction_errors = np.linalg.norm(test_vectors - test_decoded, axis=1)
        avg_error = np.mean(reconstruction_errors)
        logger.info(f"âœ… æ¸¬è©¦è§£ç¢¼æˆåŠŸï¼Œå¹³å‡é‡å»ºèª¤å·®: {avg_error:.6f}")
        
        # ç·¨ç¢¼æ‰€æœ‰å‘é‡
        logger.info("ğŸ”¢ å°æ‰€æœ‰å‘é‡é€²è¡Œ PQ ç·¨ç¢¼...")
        pq_codes = pq_model.encode(vectors)
        logger.info(f"âœ… ç·¨ç¢¼å®Œæˆï¼Œå½¢ç‹€: {pq_codes.shape}")
        
        # æ¸¬è©¦ç·¨ç¢¼ä¸€è‡´æ€§
        logger.info("ğŸ” æ¸¬è©¦ç·¨ç¢¼ä¸€è‡´æ€§...")
        re_encoded = pq_model.encode(test_vectors)
        if np.array_equal(test_codes, re_encoded):
            logger.info("âœ… ç·¨ç¢¼ä¸€è‡´æ€§æª¢æŸ¥é€šé")
        else:
            logger.error("âŒ ç·¨ç¢¼ä¸€è‡´æ€§æª¢æŸ¥å¤±æ•—")
            return False
        
        # å‚™ä»½åŸå§‹æ–‡ä»¶
        logger.info("ğŸ’¾ å‚™ä»½åŸå§‹æ–‡ä»¶...")
        pq_model_path = index_dir / "pq_model.pkl"
        pq_codes_path = index_dir / "pq_codes.bin"
        
        if pq_model_path.exists():
            backup_path = pq_model_path.with_suffix('.pkl.backup')
            pq_model_path.rename(backup_path)
            logger.info(f"  - å‚™ä»½ PQ æ¨¡å‹: {backup_path}")
        
        if pq_codes_path.exists():
            backup_path = pq_codes_path.with_suffix('.bin.backup')
            pq_codes_path.rename(backup_path)
            logger.info(f"  - å‚™ä»½ PQ ç·¨ç¢¼: {backup_path}")
        
        # ä¿å­˜æ–°çš„ PQ æ¨¡å‹å’Œç·¨ç¢¼
        logger.info("ğŸ’¾ ä¿å­˜ä¿®å¾©å¾Œçš„ PQ æ¨¡å‹...")
        persist.save_pq_codebook(str(pq_model_path), pq_model)
        persist.save_pq_codes(str(pq_codes_path), pq_codes)
        
        # ç«‹å³é©—è­‰ä¿å­˜å’ŒåŠ è¼‰
        logger.info("ğŸ” é©—è­‰ä¿å­˜å’ŒåŠ è¼‰...")
        loaded_pq_model = persist.load_pq_codebook(str(pq_model_path))
        loaded_pq_codes = persist.load_pq_codes(str(pq_codes_path), len(vectors), n_subvectors)
        
        # é©—è­‰åŠ è¼‰çš„æ¨¡å‹
        test_codes_loaded = loaded_pq_model.encode(test_vectors)
        if np.array_equal(test_codes, test_codes_loaded):
            logger.info("âœ… åŠ è¼‰å¾Œç·¨ç¢¼ä¸€è‡´æ€§æª¢æŸ¥é€šé")
        else:
            logger.error("âŒ åŠ è¼‰å¾Œç·¨ç¢¼ä¸€è‡´æ€§æª¢æŸ¥å¤±æ•—")
            return False
        
        # é©—è­‰åŠ è¼‰çš„ç·¨ç¢¼
        if np.array_equal(pq_codes[:5], loaded_pq_codes[:5]):
            logger.info("âœ… PQ ç·¨ç¢¼æ–‡ä»¶ä¸€è‡´æ€§æª¢æŸ¥é€šé")
        else:
            logger.error("âŒ PQ ç·¨ç¢¼æ–‡ä»¶ä¸€è‡´æ€§æª¢æŸ¥å¤±æ•—")
            return False
        
        # æ¸¬è©¦è·é›¢è¨ˆç®—
        logger.info("ğŸ¯ æ¸¬è©¦è·é›¢è¨ˆç®—...")
        query_vector = test_vectors[0]
        distance_table = loaded_pq_model.compute_distance_table(query_vector)
        
        for i in range(1, 5):
            exact_dist = np.sum((query_vector - test_vectors[i]) ** 2)
            pq_dist = loaded_pq_model.asymmetric_distance_sq(
                test_codes_loaded[i:i+1], distance_table
            )[0]
            ratio = pq_dist / exact_dist if exact_dist > 0 else float('inf')
            logger.info(f"  æ¸¬è©¦å‘é‡ {i}: ç²¾ç¢º={exact_dist:.6f}, PQ={pq_dist:.6f}, æ¯”ä¾‹={ratio:.4f}")
        
        logger.info("ğŸ‰ PQ æ¨¡å‹ä¿®å¾©å®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ PQ æ¨¡å‹ä¿®å¾©å¤±æ•—: {e}", exc_info=True)
        return False

def main():
    """ä¸»å‡½æ•¸"""
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python pq_debug_test.py <collection_name>")
        sys.exit(1)
    
    collection_name = sys.argv[1]
    
    success = fix_pq_model(collection_name)
    if success:
        print(f"\nâœ… é›†åˆ '{collection_name}' çš„ PQ æ¨¡å‹ä¿®å¾©æˆåŠŸï¼")
        print("ç¾åœ¨å¯ä»¥é‡æ–°é‹è¡Œè¨ºæ–·æ¸¬è©¦:")
        print(f"python pq_debug_test.py {collection_name}")
    else:
        print(f"\nâŒ é›†åˆ '{collection_name}' çš„ PQ æ¨¡å‹ä¿®å¾©å¤±æ•—ï¼")
        sys.exit(1)

if __name__ == "__main__":
    main()