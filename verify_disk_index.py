#!/usr/bin/env python3
"""
é©—è­‰ç£ç¢Ÿç´¢å¼•æ–‡ä»¶çš„è…³æœ¬
æª¢æŸ¥ç´¢å¼•æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨æ–¼ç£ç¢Ÿä¸Šï¼Œä¸¦é©—è­‰å…¶çµæ§‹
"""

import os
import sys
import numpy as np
from pathlib import Path

# Add project root to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from pydiskann.io.diskann_persist import MMapNodeReader, DiskANNPersist
import json

def verify_index_file(index_path, meta_path=None):
    """é©—è­‰ç´¢å¼•æ–‡ä»¶"""
    print(f"ğŸ” é©—è­‰ç´¢å¼•æ–‡ä»¶: {index_path}")
    print("=" * 60)
    
    # 1. æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(index_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {index_path}")
        return False
    
    # 2. ç²å–æ–‡ä»¶ä¿¡æ¯
    stat = os.stat(index_path)
    file_size = stat.st_size
    print(f"âœ… æ–‡ä»¶å­˜åœ¨")
    print(f"   - å¤§å°: {file_size:,} bytes ({file_size / 1024 / 1024:.2f} MB)")
    print(f"   - ä¿®æ”¹æ™‚é–“: {stat.st_mtime}")
    
    # 3. è®€å–å…ƒæ•¸æ“š
    if meta_path and os.path.exists(meta_path):
        with open(meta_path, 'r') as f:
            meta = json.load(f)
        print(f"\nğŸ“‹ å…ƒæ•¸æ“šè³‡æ–™:")
        for key, value in meta.items():
            print(f"   - {key}: {value}")
        
        dim = meta.get('dimension', meta.get('D', 128))
        R = meta.get('R', 32)
        N = meta.get('N', 0)
    else:
        print("\nâš ï¸  æœªæ‰¾åˆ° meta.jsonï¼Œä½¿ç”¨é è¨­å€¼")
        dim = 128
        R = 32
        N = 0
    
    # 4. è¨ˆç®—é æœŸæ–‡ä»¶å¤§å°
    record_size = 4 * (dim + R)  # float32 * dim + uint32 * R
    if N > 0:
        expected_size = N * record_size
        print(f"\nğŸ“ æ–‡ä»¶çµæ§‹é©—è­‰:")
        print(f"   - å‘é‡ç¶­åº¦ (D): {dim}")
        print(f"   - æœ€å¤§å‡ºåº¦ (R): {R}")
        print(f"   - ç¯€é»æ•¸é‡ (N): {N}")
        print(f"   - æ¯æ¢è¨˜éŒ„å¤§å°: {record_size} bytes")
        print(f"   - é æœŸæ–‡ä»¶å¤§å°: {expected_size:,} bytes ({expected_size / 1024 / 1024:.2f} MB)")
        print(f"   - å¯¦éš›æ–‡ä»¶å¤§å°: {file_size:,} bytes ({file_size / 1024 / 1024:.2f} MB)")
        
        if abs(file_size - expected_size) < 1024:  # å…è¨± 1KB èª¤å·®
            print(f"   âœ… æ–‡ä»¶å¤§å°ç¬¦åˆé æœŸ")
        else:
            print(f"   âš ï¸  æ–‡ä»¶å¤§å°èˆ‡é æœŸä¸ç¬¦ (å·®ç•°: {abs(file_size - expected_size):,} bytes)")
    
    # 5. å˜—è©¦ä½¿ç”¨ MMapNodeReader è®€å–
    print(f"\nğŸ’¾ æ¸¬è©¦ç£ç¢Ÿè®€å– (MMap):")
    try:
        reader = MMapNodeReader(index_path, dim=dim, R=R)
        print(f"   âœ… MMapNodeReader åˆå§‹åŒ–æˆåŠŸ")
        
        # è®€å–ç¬¬ä¸€å€‹ç¯€é»
        if N > 0:
            print(f"\nğŸ“– è®€å–ç¯€é»æ¨£æœ¬:")
            for node_id in [0, min(100, N-1), N-1]:
                if node_id < N:
                    vec, neighbors = reader.get_node(node_id)
                    print(f"   - ç¯€é» {node_id}:")
                    print(f"     * å‘é‡å½¢ç‹€: {vec.shape}, é¡å‹: {vec.dtype}")
                    print(f"     * å‘é‡å‰5å€‹å€¼: {vec[:5]}")
                    print(f"     * é„°å±…æ•¸é‡: {len(neighbors)}")
                    print(f"     * é„°å±…å‰5å€‹: {neighbors[:5].tolist()}")
                    print(f"     * éé›¶é„°å±…: {neighbors[neighbors > 0].tolist()}")
        
        # æ¸¬è©¦éš¨æ©Ÿè®€å–
        print(f"\nğŸ² æ¸¬è©¦éš¨æ©Ÿè®€å–æ€§èƒ½:")
        import time
        test_nodes = [0, N//4, N//2, 3*N//4, N-1] if N > 0 else [0]
        test_nodes = [n for n in test_nodes if n < N]
        
        times = []
        for node_id in test_nodes:
            t0 = time.perf_counter()
            vec, neighbors = reader.get_node(node_id)
            t1 = time.perf_counter()
            times.append((t1 - t0) * 1000)  # ms
            print(f"   - ç¯€é» {node_id}: {times[-1]:.4f} ms")
        
        if times:
            avg_time = np.mean(times)
            print(f"   - å¹³å‡è®€å–æ™‚é–“: {avg_time:.4f} ms")
        
        reader.close()
        print(f"   âœ… ç£ç¢Ÿè®€å–æ¸¬è©¦æˆåŠŸ")
        
    except Exception as e:
        print(f"   âŒ è®€å–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 6. é©—è­‰æ–‡ä»¶ç¢ºå¯¦å¯«å…¥ç£ç›¤ï¼ˆä¸æ˜¯å…§å­˜æ˜ å°„ï¼‰
    print(f"\nğŸ’¿ é©—è­‰æ–‡ä»¶å­˜å„²ä½ç½®:")
    try:
        # ç²å–æ–‡ä»¶æ‰€åœ¨çš„è¨­å‚™
        import subprocess
        result = subprocess.run(['df', index_path], capture_output=True, text=True)
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            if len(lines) > 1:
                print(f"   {lines[1]}")
        
        # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„åœ¨ç£ç¢Ÿä¸Šï¼ˆé€šéè®€å–ä¸€å°éƒ¨åˆ†ï¼‰
        with open(index_path, 'rb') as f:
            f.seek(0)
            header = f.read(min(1024, file_size))
            print(f"   âœ… æ–‡ä»¶å¯ä»¥æ­£å¸¸è®€å–ï¼ˆå‰ {len(header)} bytesï¼‰")
            print(f"   - å‰16 bytes (hex): {header[:16].hex()}")
            
    except Exception as e:
        print(f"   âš ï¸  ç„¡æ³•é©—è­‰å­˜å„²ä½ç½®: {e}")
    
    print("\n" + "=" * 60)
    print("âœ… é©—è­‰å®Œæˆ")
    return True

if __name__ == "__main__":
    # æª¢æŸ¥é è¨­ç´¢å¼•
    default_index = Path("collections/default/index/index.dat")
    default_meta = Path("collections/default/index/meta.json")
    
    if default_index.exists():
        verify_index_file(str(default_index), str(default_meta) if default_meta.exists() else None)
    else:
        print("âŒ æœªæ‰¾åˆ°é è¨­ç´¢å¼•æ–‡ä»¶")
        print("   è«‹å…ˆé‹è¡Œ benchmark æˆ–å»ºç«‹ç´¢å¼•")
        
        # æä¾›ä½¿ç”¨æŒ‡å¼•
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("  python verify_disk_index.py")
        print("  æˆ–æŒ‡å®šç´¢å¼•è·¯å¾‘:")
        print("  python verify_disk_index.py <index_path> [meta_path]")

