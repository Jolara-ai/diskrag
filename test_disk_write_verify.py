#!/usr/bin/env python3
"""
æ¸¬è©¦ç£ç¢Ÿå¯«å…¥å’Œé©—è­‰è…³æœ¬
å‰µå»ºä¸€å€‹å°è¦æ¨¡çš„ç´¢å¼•ä¸¦é©—è­‰å®ƒçœŸçš„å¯«å…¥ç£ç›¤
"""

import os
import sys
import numpy as np
import time
from pathlib import Path

# Add project root to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from pydiskann.vamana_graph import build_vamana
from pydiskann.io.diskann_persist import DiskANNPersist, MMapNodeReader
from pydiskann.vamana_graph import beam_search_from_disk

def test_disk_write_and_verify():
    """æ¸¬è©¦ç£ç¢Ÿå¯«å…¥å’Œé©—è­‰"""
    print("ğŸ§ª æ¸¬è©¦ç£ç¢Ÿç´¢å¼•å¯«å…¥å’Œé©—è­‰")
    print("=" * 60)
    
    # 1. å‰µå»ºå°è¦æ¨¡æ¸¬è©¦æ•¸æ“š
    print("\nğŸ“Š å‰µå»ºæ¸¬è©¦æ•¸æ“š...")
    n_points = 1000
    dim = 128
    np.random.seed(42)
    points = np.random.randn(n_points, dim).astype(np.float32)
    print(f"   - ç¯€é»æ•¸: {n_points}")
    print(f"   - ç¶­åº¦: {dim}")
    
    # 2. æ§‹å»ºåœ–
    print("\nğŸ—ï¸  æ§‹å»º Vamana åœ–...")
    start = time.time()
    graph = build_vamana(points, R=16, L=32, alpha=1.2, show_progress=False)
    build_time = time.time() - start
    print(f"   âœ… æ§‹å»ºå®Œæˆï¼Œè€—æ™‚: {build_time:.2f}ç§’")
    print(f"   - ç¯€é»æ•¸: {len(graph.nodes)}")
    avg_degree = sum(len(n.neighbors) for n in graph.nodes.values()) / len(graph.nodes)
    print(f"   - å¹³å‡å‡ºåº¦: {avg_degree:.2f}")
    
    # 3. ä¿å­˜åˆ°ç£ç¢Ÿ
    index_path = "test_vamana_index.bin"
    print(f"\nğŸ’¾ ä¿å­˜ç´¢å¼•åˆ°ç£ç¢Ÿ: {index_path}")
    
    # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(index_path):
        old_size = os.stat(index_path).st_size
        print(f"   âš ï¸  æ–‡ä»¶å·²å­˜åœ¨ï¼Œå¤§å°: {old_size:,} ä½å…ƒçµ„")
        os.remove(index_path)
        print(f"   ğŸ—‘ï¸  å·²åˆªé™¤èˆŠæª”æ¡ˆ")
    
    # ä¿å­˜ç´¢å¼•
    persist = DiskANNPersist(dim=dim, R=16)
    start_save = time.time()
    persist.save_index(index_path, graph)
    save_time = time.time() - start_save
    
    # é©—è­‰æ–‡ä»¶å·²å‰µå»º
    if not os.path.exists(index_path):
        print(f"   âŒ æ–‡ä»¶ä¿å­˜å¤±æ•—ï¼")
        return False
    
    stat = os.stat(index_path)
    file_size = stat.st_size
    print(f"   âœ… æ–‡ä»¶ä¿å­˜æˆåŠŸ")
    print(f"   - ä¿å­˜æ™‚é–“: {save_time:.4f}ç§’")
    print(f"   - æ–‡ä»¶å¤§å°: {file_size:,} ä½å…ƒçµ„ ({file_size / 1024 / 1024:.2f} MB)")
    
    # 4. é©—è­‰æ–‡ä»¶çµæ§‹
    print(f"\nğŸ“ é©—è­‰æ–‡ä»¶çµæ§‹...")
    record_size = 4 * (dim + 16)  # float32 * dim + uint32 * R
    expected_size = n_points * record_size
    print(f"   - æ¯æ¢è¨˜éŒ„å¤§å°: {record_size} ä½å…ƒçµ„")
    print(f"   - é æœŸæ–‡ä»¶å¤§å°: {expected_size:,} ä½å…ƒçµ„")
    print(f"   - å¯¦éš›æ–‡ä»¶å¤§å°: {file_size:,} ä½å…ƒçµ„")
    
    if abs(file_size - expected_size) < 1024:
        print(f"   âœ… æ–‡ä»¶å¤§å°ç¬¦åˆé æœŸ")
    else:
        print(f"   âš ï¸  æ–‡ä»¶å¤§å°å·®ç•°: {abs(file_size - expected_size):,} ä½å…ƒçµ„")
    
    # 5. é©—è­‰æ–‡ä»¶å­˜å„²ä½ç½®
    print(f"\nğŸ’¿ é©—è­‰æ–‡ä»¶å„²å­˜ä½ç½®...")
    try:
        import subprocess
        result = subprocess.run(['df', index_path], capture_output=True, text=True)
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            if len(lines) > 1:
                parts = lines[1].split()
                print(f"   - æ–‡ä»¶ç³»çµ±: {parts[0]}")
                print(f"   - æ›è¼‰é»: {parts[-1]}")
                print(f"   - ç¸½å®¹é‡: {parts[1]}")
                print(f"   - å·²ä½¿ç”¨: {parts[2]}")
                print(f"   - å¯ç”¨ç©ºé–“: {parts[3]}")
    except Exception as e:
        print(f"   âš ï¸  ç„¡æ³•ç²å–æ–‡ä»¶ç³»çµ±ä¿¡æ¯: {e}")
    
    # 6. ä½¿ç”¨ MMapNodeReader è®€å–
    print(f"\nğŸ“– æ¸¬è©¦ç£ç¢Ÿè®€å– (MMap)...")
    try:
        reader = MMapNodeReader(index_path, dim=dim, R=16)
        print(f"   âœ… MMapNodeReader åˆå§‹åŒ–æˆåŠŸ")
        
        # è®€å–å¹¾å€‹ç¯€é»é©—è­‰
        print(f"\n   ğŸ” é©—è­‰ç¯€é»è®€å–:")
        test_nodes = [0, n_points//4, n_points//2, 3*n_points//4, n_points-1]
        for node_id in test_nodes:
            if node_id < n_points:
                vec, neighbors = reader.get_node(node_id)
                print(f"   - ç¯€é» {node_id}:")
                print(f"     * å‘é‡å½¢ç‹€: {vec.shape}, dtype: {vec.dtype}")
                print(f"     * é„°å±…æ•¸é‡: {len(neighbors)}")
                valid_neighbors = neighbors[neighbors > 0]
                print(f"     * æœ‰æ•ˆé„°å±…: {len(valid_neighbors)} å€‹")
                if len(valid_neighbors) > 0:
                    print(f"     * é„°å±… ID: {valid_neighbors[:5].tolist()}")
        
        # 7. æ¸¬è©¦æœç´¢
        print(f"\nğŸ” æ¸¬è©¦ç£ç¢Ÿæœç´¢...")
        query = np.random.randn(dim).astype(np.float32)
        start_node = graph.medoid_idx if hasattr(graph, 'medoid_idx') else 0
        
        search_times = []
        for beam_width in [8, 16]:
            t0 = time.perf_counter()
            results = beam_search_from_disk(reader, query, start_node, beam_width=beam_width, k=5)
            t1 = time.perf_counter()
            search_time = (t1 - t0) * 1000  # ms
            search_times.append(search_time)
            print(f"   - Beam={beam_width}: {search_time:.4f} ms, æ‰¾åˆ° {len(results)} å€‹çµæœ")
            if results:
                print(f"     * Top-3: {[idx for _, idx in results[:3]]}")
        
        reader.close()
        print(f"   âœ… ç£ç¢Ÿæœç´¢æ¸¬è©¦æˆåŠŸ")
        
    except Exception as e:
        print(f"   âŒ è®€å–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 8. é©—è­‰æ–‡ä»¶ç¢ºå¯¦å¯«å…¥ç£ç¢Ÿï¼ˆè®€å–åŸå§‹å­—ç¯€ï¼‰
    print(f"\nğŸ”¬ é©—è­‰æ–‡ä»¶å…§å®¹...")
    try:
        with open(index_path, 'rb') as f:
            # è®€å–ç¬¬ä¸€å€‹ç¯€é»çš„å‘é‡
            first_vec_bytes = f.read(4 * dim)
            first_vec = np.frombuffer(first_vec_bytes, dtype=np.float32)
            
            # è®€å–ç¬¬ä¸€å€‹ç¯€é»çš„é„°å±…
            first_neighbors_bytes = f.read(4 * 16)
            first_neighbors = np.frombuffer(first_neighbors_bytes, dtype=np.uint32)
            
            print(f"   - ç¬¬ä¸€å€‹ç¯€é»çš„å‘é‡ (å‰5å€‹å€¼): {first_vec[:5]}")
            print(f"   - ç¬¬ä¸€å€‹ç¯€é»çš„é„°å±…: {first_neighbors[first_neighbors > 0].tolist()}")
            
            # èˆ‡å…§å­˜ä¸­çš„åœ–æ¯”è¼ƒ
            if 0 in graph.nodes:
                mem_vec = graph.nodes[0].vector
                mem_neighbors = list(graph.nodes[0].neighbors)
                
                vec_match = np.allclose(first_vec, mem_vec, atol=1e-6)
                neighbors_match = set(first_neighbors[first_neighbors > 0]) == set(mem_neighbors)
                
                print(f"   - å‘é‡åŒ¹é…: {'âœ…' if vec_match else 'âŒ'}")
                print(f"   - é„°å±…åŒ¹é…: {'âœ…' if neighbors_match else 'âŒ'}")
                
                if vec_match and neighbors_match:
                    print(f"   âœ… æ–‡ä»¶å…§å®¹èˆ‡å…§å­˜åœ–ä¸€è‡´")
                else:
                    print(f"   âš ï¸  æ–‡ä»¶å…§å®¹èˆ‡å…§å­˜åœ–ä¸ä¸€è‡´")
    except Exception as e:
        print(f"   âš ï¸  ç„¡æ³•é©—è­‰æ–‡ä»¶å…§å®¹: {e}")
    
    print("\n" + "=" * 60)
    print("âœ… æ¸¬è©¦å®Œæˆ")
    print(f"\nğŸ“ çµè«–:")
    print(f"   - ç´¢å¼•æ–‡ä»¶å·²æˆåŠŸå¯«å…¥ç£ç¢Ÿ")
    print(f"   - æ–‡ä»¶å¤§å°: {file_size:,} ä½å…ƒçµ„ ({file_size / 1024 / 1024:.2f} MB)")
    print(f"   - å¯ä»¥ä½¿ç”¨ MMapNodeReader å¾ç£ç¢Ÿè®€å–")
    print(f"   - ç£ç¢Ÿæœç´¢åŠŸèƒ½æ­£å¸¸")
    
    # è©¢å•æ˜¯å¦ä¿ç•™æ–‡ä»¶
    print(f"\nğŸ’¡ æç¤º: æ¸¬è©¦æª”æ¡ˆ '{index_path}' å·²å‰µå»º")
    print(f"   å¦‚éœ€ä¿ç•™ç”¨æ–¼é€²ä¸€æ­¥æ¸¬è©¦ï¼Œè«‹ä¸è¦åˆªé™¤")
    
    return True

if __name__ == "__main__":
    success = test_disk_write_and_verify()
    sys.exit(0 if success else 1)

